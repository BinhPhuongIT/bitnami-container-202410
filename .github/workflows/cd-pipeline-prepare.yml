name: '[CI/CD] CD Pipeline Prepare'
run-name: "${{ github.event_name == 'workflow_dispatch' && format('[CD] Retrying SHA: {0}', inputs.sha) || '' }}"
on: # rebuild any PRs and main branch changes
  workflow_dispatch:
    inputs:
      sha:
        description: 'Commit to retry'
        required: true
        default: 'HEAD'
  push:
    branches:
      - main
    paths:
      - 'bitnami/**'
env:
  CSP_API_URL: https://console.cloud.vmware.com
  CSP_API_TOKEN: ${{ secrets.CSP_API_TOKEN }}
  VIB_PUBLIC_URL: https://cp.bromelia.vmware.com
jobs:
  prepare:
    runs-on: ubuntu-latest
    name: Get modified containers path
    if: |
      github.event_name == 'workflow_dispatch' ||
      (github.event.head_commit.author.username == 'bitnami-bot' && github.event.forced == false)
    outputs:
      result: ${{ steps.get-publish-metadata.outputs.result }}
      containers: ${{ steps.get-publish-metadata.outputs.containers }}
    steps:
      - name: Install s3cmd
        run: sudo apt-get install -y s3cmd
      - name: Checkout Repository
        uses: actions/checkout@v3
        # Full history is not required anymore
        with:
          ref: ${{github.event_name == 'workflow_dispatch' && inputs.sha || '' }}
          fetch-depth: 1
      - id: get-publish-metadata
        name: Get information about containers to publish
        env:
          GITHUB_COMMITS: ${{ github.event_name == 'workflow_dispatch' && format('[{{"id":"{0}"}}]', inputs.sha) || toJson(github.event.commits) }}
        run: |
          # Get all commits associated to the push
          commits=($(echo "${GITHUB_COMMITS}" | jq -r '.[] | .id'))
          containers=()
          for commit in "${commits[@]}"; do
            containers_in_commit=()
            # Using the Github API to detect the files changed as git merge-base stops working when the branch is behind
            URL="https://api.github.com/repos/${{ github.repository }}/commits/${commit}"
            files_changed_data=$(curl -s --header 'authorization: Bearer ${{ secrets.GITHUB_TOKEN }}' -X GET -G "$URL")
            files_changed="$(echo $files_changed_data | jq -r '.files[] | .filename')"
            # Adding || true to avoid "Process exited with code 1" errors
            containers_in_commit+=($(echo "$files_changed" | xargs dirname | grep -o "^bitnami/[^/]*/[^/]*/[^/]*" | sort | uniq || true))
            for container in "${containers_in_commit[@]}"; do
              if [[ ! $containers =~ (^|[[:space:]])$container($|[[:space:]]) ]]; then
                # Avoid duplicates
                containers+=("${container}")
                if [[ -d "${container}" ]]; then
                  tag="$(grep -oE "org.opencontainers.image.ref.name=\".+\"" ${container}/Dockerfile | sed -nr "s|org.opencontainers.image.ref.name=\"(.+)\"|\1|p")"
                  if [[ -z "${tag}" ]]; then
                    echo "No tag found for: ${container}"
                  else
                    name="$(grep -oE "org.opencontainers.image.title=\".+\"" ${container}/Dockerfile | sed -nr "s|org.opencontainers.image.title=\"(.+)\"|\1|p")"
                    app_version="$(grep -oE "org.opencontainers.image.version=\".+\"" ${container}/Dockerfile | sed -nr "s|org.opencontainers.image.version=\"(.+)\"|\1|p")"
                    rolling_tags="$(yq '.rolling-tags' ${container}/tags-info.yaml -o json | jq -c)"
                    branch="$(echo "${container}" | awk -F '/' '{print $3}')"
                    container_json=$(jq -n '{"name": $name, "path": $path, "branch": $branch, "app_version": $app_version, "tag": $tag, "rolling_tags": $rolling_tags}' --arg name "$name" --arg app_version "$app_version" --arg branch "$branch" --arg path "$container" --arg tag "$tag" --argjson rolling_tags "$rolling_tags")
                    containers_json+=("${container_json}")
                  fi
                fi
              fi
            done
          done

          if [[ "${#containers[@]}" -le "0" ]]; then
            echo "No changes detected in containers. The rest of the steps will be skipped."
            echo "result=skip" >> $GITHUB_OUTPUT
          else
            containers_json=$(printf "%s\n" "${containers_json[@]}" | jq -s .)
            echo "result=ok" >> $GITHUB_OUTPUT
            echo "${containers_json}" > publish-metadata.json
          fi
      - name: 'Getting 3rd party packages for OSSPI'
        if: ${{ steps.get-publish-metadata.outputs.result == 'ok' }}
        run: |
          CONTAINERS_TO_PUBLISH=$(cat publish-metadata.json | jq -cr '.[]')
          for CONTAINER in "${CONTAINERS_TO_PUBLISH[@]}"; do
            # If it's set from outside, can be changed
            ARCH="${ARCH:-amd64}"
            IMAGE_NAME=$(echo $CONTAINER | jq -cr '.tag')
            VERSION=$(echo $CONTAINER | jq -cr '.app_version')
            ASSET=$(echo $CONTAINER | jq -cr '.name')
            CLEANED_IMAGE_NAME=${IMAGE_NAME#"$VERSION-"}
            # split by -
            ASSET_DATA=(${CLEANED_IMAGE_NAME//-/ })
            OS=${ASSET_DATA[0]}-${ASSET_DATA[1]}
            REVISION=(${ASSET_DATA[2]/r/})

            COMPONENTS_FILES=""
            #COMPONENTS_FILES=$(s3cmd ls -l --access_key=${{ secrets.AWS_ACCESS_KEY_ID }} --secret_key=${{ secrets.AWS_SECRET_ACCESS_KEY }} s3://${{ secrets.AWS_S3_BUCKET }}/$ASSET/$VERSION/$OS/$ARCH/$REVISION/ | grep "components.json" | wc -l)
            # If the components.json file, so it seems has external packages
            if [[ $COMPONENTS_FILES -gt 0 ]]; then
              # s3cmd get --access_key=${{ secrets.AWS_ACCESS_KEY_ID }} --secret_key=${{ secrets.AWS_SECRET_ACCESS_KEY }} s3://${{ secrets.AWS_S3_BUCKET }}/$ASSET/$VERSION/$OS/$ARCH/$REVISION/components.json components.json

              declare -A PACKAGES
              # Iterating over the external components to get the involved elements
              while read -r COMPONENT_ID; do
                COMPONENT_VERSION_FULL=$(jq -c ".$COMPONENT_ID.version" components.json)
                COMPONENT_VERSION_FULL=(${COMPONENT_VERSION_FULL//"\""/})

                # Sanityzing strings
                COMPONENT_ID=(${COMPONENT_ID//"\""/})
                #split by "-"
                COMPONENT_PARTS=(${COMPONENT_VERSION_FULL//-/ })
                COMPONENT_VERSION=${COMPONENT_PARTS[0]}

                COMPILATION_RECIPE=""
                #COMPILATION_RECIPE=$(s3cmd ls -l --access_key=${{ secrets.AWS_ACCESS_KEY_ID }} --secret_key=${{ secrets.AWS_SECRET_ACCESS_KEY }} s3://${{ secrets.AWS_S3_BUCKET }}/$COMPONENT_ID/$COMPONENT_VERSION/$OS/$ARCH/ | grep "compilation-recipe.json" | wc -l)
                # If the components.json file, so it seems has external packages
                # if [[ $COMPILATION_RECIPE -gt 0 ]]; then
                #   s3cmd get --access_key=${{ secrets.AWS_ACCESS_KEY_ID }} --secret_key=${{ secrets.AWS_SECRET_ACCESS_KEY }} s3://${{ secrets.AWS_S3_BUCKET }}/$COMPONENT_ID/$COMPONENT_VERSION/$OS/$ARCH/compilation-recipe.json compilation-recipe.json
                # else
                #   s3cmd get --access_key=${{ secrets.AWS_ACCESS_KEY_ID }} --secret_key=${{ secrets.AWS_SECRET_ACCESS_KEY }} s3://${{ secrets.AWS_S3_BUCKET }}/$COMPONENT_ID/$COMPONENT_VERSION-${COMPONENT_PARTS[1]}/$OS/$ARCH/compilation-recipe.json compilation-recipe.json
                # fi
                # now getting each component to be reported
                while read -r JSON_PACKAGE; do
                  PACKAGE_ID=$(echo "$JSON_PACKAGE" | jq -r '.id' )
                  PACKAGE_VERSION=$(echo "$JSON_PACKAGE" | jq -r '.version' )
                  PACKAGE_URL=$(echo "$JSON_PACKAGE" | jq -r '.source.upstreamSourceUrl')
                  PACKAGES[$PACKAGE_ID]="$PACKAGE_VERSION $PACKAGE_URL"
                done <<<"$(jq -c '.components[]' compilation-recipe.json)"
                rm compilation-recipe.json
              done <<<"$(jq -c 'keys[]' components.json)"

              # Now creating the JSON file with the needed transformations
              JSON_PACKAGES=()
              for PACKAGE_ID in "${!PACKAGES[@]}"
              do
                VALUES=(${PACKAGES[$PACKAGE_ID]// / })
                CLEANED_URL=(${VALUES[1]/git+/})
                if [ -z "$CLEANED_URL" ]
                then
                  echo "[WARNING] The URL for $PACKAGE_ID:${VALUES[0]} is missing in the recipe"
                else
                  JSON_PACKAGES+=($(jq -n '{"_unique_id": $uniqueID, "name": $name, "version": $version, "url": $url, "repository": "other"}' --arg uniqueID "other:$PACKAGE_ID:${VALUES[0]}" --arg name $PACKAGE_ID --arg version ${VALUES[0]} --arg url $CLEANED_URL))
                fi
              done
              JSON_ARRAY=$(printf "%s" "${JSON_PACKAGES[@]}" | jq -s)
              echo "$JSON_ARRAY" > ${container}/packages.json
              # s3cmd put --access_key=${{ secrets.AWS_ACCESS_KEY_ID }} --secret_key=${{ secrets.AWS_SECRET_ACCESS_KEY }} ${container}/packages.json s3://${{ secrets.AWS_S3_BUCKET }}/$ASSET/$VERSION/$OS/$ARCH/$REVISION/packages.json
            else
              echo "$IMAGE_NAME:$VERSION doesn't have external components.json"
            fi
          done
      - uses: actions/upload-artifact@v3
        if: ${{ steps.get-publish-metadata.outputs.result == 'ok' }}
        with:
          name: publish-metadata.json
          path: ./publish-metadata.json
      - uses: actions/upload-artifact@v3
        if: ${{ steps.get-publish-metadata.outputs.result == 'ok' }}
        with:
          name: package
          path: ${{github.workspace}}